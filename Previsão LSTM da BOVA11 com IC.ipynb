{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555ac963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from tensorflow.keras.saving import save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ba3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURAÇÃO INICIAL ---\n",
    "df = yf.Ticker('BOVA11.SA')\n",
    "hoje = datetime.date.today()\n",
    "start_date = hoje.replace(year=hoje.year - 4, month=1, day=1)\n",
    "# Definir o período desejado (de 2018 até hoje)\n",
    "start_date = '2018-01-01'\n",
    "end_date = pd.Timestamp.today().strftime('%Y-%m-%d')\n",
    "\n",
    "bd = df.history(start=start_date, end=end_date)\n",
    "bd_2 = df.history(period=\"2d\", interval='1m')\n",
    "\n",
    "if bd.index[-1].date() != bd_2.index[-1].date():\n",
    "    bd = pd.concat([bd, bd_2.tail(1)], axis=0)\n",
    "\n",
    "bd['Date'] = pd.to_datetime(bd.index).date \n",
    "bd.reset_index(drop=True, inplace=True)\n",
    "bd_fec = bd[['Date','Close']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90645d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ESCALONAMENTO MANUAL ---\n",
    "me = bd['Close'].mean()\n",
    "amp = bd['Close'].max() - bd['Close'].min()\n",
    "df_scaled = ((bd['Close'] - me)/amp).to_numpy().reshape(-1, 1)\n",
    "\n",
    "def create_df(df, steps=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(df)-steps):\n",
    "        a = df[i:(i+steps), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(df[i+steps, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "steps = 15\n",
    "X, Y = create_df(df_scaled, steps)\n",
    "train_size = len(X) - 25\n",
    "Xtrain = X[0:train_size]\n",
    "Ytrain = Y[0:train_size]\n",
    "Xtest = X[train_size:]\n",
    "Ytest = Y[train_size:]\n",
    "\n",
    "# Reshape\n",
    "Xtrain = Xtrain.reshape(Xtrain.shape[0], Xtrain.shape[1], 1)\n",
    "Xtest = Xtest.reshape(Xtest.shape[0], Xtest.shape[1], 1)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dc7d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# --- MODELO ---\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, activation=LeakyReLU(alpha=0.04), return_sequences=True, input_shape=(steps, 1)))\n",
    "model.add(Dropout(0.03))\n",
    "model.add(LSTM(64, activation=LeakyReLU(alpha=0.03), return_sequences=True))\n",
    "model.add(Dropout(0.02))\n",
    "model.add(LSTM(32, activation=LeakyReLU(alpha=0.02), return_sequences=False))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(1, activation=LeakyReLU(alpha=0.01)))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=50,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "validation = model.fit(\n",
    "    Xtrain, Ytrain,\n",
    "    validation_data=(Xtest, Ytest),\n",
    "    epochs=100, # Reduzi para teste rápido, mantenha o seu valor original\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stopping_callback],\n",
    "    verbose=0 # Deixei 0 para limpar o output, mude para 1 se quiser ver o treino\n",
    ")\n",
    "\n",
    "# 1. Pede para o modelo avaliar os dados de teste AGORA\n",
    "resultado_atual = model.evaluate(Xtest, Ytest, verbose=0)\n",
    "loss_atual = resultado_atual[0] if isinstance(resultado_atual, list) else resultado_atual\n",
    "\n",
    "# 2. Busca qual foi o menor valor de 'val_loss' registrado no histórico\n",
    "melhor_loss_historico = min(validation.history['val_loss'])\n",
    "pior_loss_historico = validation.history['val_loss'][-1] # O da última época\n",
    "\n",
    "print(f\"Loss do modelo atual na memória: {loss_atual:.6f}\")\n",
    "print(f\"Melhor Loss registrado no histórico: {melhor_loss_historico:.6f}\")\n",
    "print(f\"Loss da última época (100): {pior_loss_historico:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f094ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TÉCNICA: MONTE CARLO DROPOUT (Incerteza do Modelo)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"Iniciando Simulação Monte Carlo Dropout...\")\n",
    "\n",
    "n_future = 10\n",
    "n_simulations = 500  # Quantas \"versões\" da rede vamos consultar\n",
    "mc_predictions = []  # Vai guardar todas as simulações (500 x 10)\n",
    "\n",
    "# Última janela conhecida (Ponto de partida)\n",
    "# Convertendo para tensor para ser compatível com a chamada direta do modelo\n",
    "initial_input_tensor = tf.convert_to_tensor(df_scaled[-steps:].reshape(1, steps, 1), dtype=tf.float32)\n",
    "\n",
    "for i in range(n_simulations):\n",
    "    # Caminho temporário para esta simulação específica\n",
    "    current_path = []\n",
    "    current_input = initial_input_tensor # Reseta para o começo a cada simulação\n",
    "    \n",
    "    for f in range(n_future):\n",
    "        # O PULO DO GATO: training=True força o Dropout a ficar ativo\n",
    "        # Isso faz com que cada loop use um conjunto diferente de neurônios\n",
    "        pred_tensor = model(current_input, training=True) \n",
    "        \n",
    "        pred_value = pred_tensor.numpy()[0][0]\n",
    "        current_path.append(pred_value)\n",
    "        \n",
    "        # Atualiza a janela deslizante para o próximo dia (Recursivo)\n",
    "        # Remove o primeiro, adiciona o novo no fim\n",
    "        new_step = tf.reshape(pred_value, (1, 1, 1))\n",
    "        current_input = tf.concat([current_input[:, 1:, :], new_step], axis=1)\n",
    "    \n",
    "    mc_predictions.append(current_path)\n",
    "\n",
    "# Transforma em array numpy [500 simulações, 10 dias]\n",
    "mc_predictions = np.array(mc_predictions)\n",
    "\n",
    "# ==============================================================================\n",
    "# CÁLCULO ESTATÍSTICO (Média +/- 1.96 SD)\n",
    "# ==============================================================================\n",
    "\n",
    "# Calcula estatísticas por dia (coluna por coluna)\n",
    "mean_preds = np.mean(mc_predictions, axis=0)\n",
    "std_preds = np.std(mc_predictions, axis=0)\n",
    "\n",
    "# Define intervalo (Assumindo Normalidade nas variações da rede)\n",
    "z_score = 1.96\n",
    "lower_bound = mean_preds - (z_score * std_preds)\n",
    "upper_bound = mean_preds + (z_score * std_preds)\n",
    "\n",
    "# Desfaz a escala (Inverse Transform)\n",
    "final_mean = mean_preds * amp + me\n",
    "final_lower = lower_bound * amp + me\n",
    "final_upper = upper_bound * amp + me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# MONTAGEM DO DATAFRAME E PLOT\n",
    "# ==============================================================================\n",
    "\n",
    "dates = pd.to_datetime(bd['Date'])\n",
    "last_date = dates.iloc[-1]\n",
    "predict_dates = pd.date_range(last_date + pd.DateOffset(1), periods=10, freq='b').tolist()\n",
    "\n",
    "df_result = pd.DataFrame({\n",
    "    'Date': predict_dates,\n",
    "    'Predict_Mean': final_mean,\n",
    "    'Lower_IC': final_lower,\n",
    "    'Upper_IC': final_upper,\n",
    "    'Std_Dev': std_preds * amp # Apenas para curiosidade\n",
    "})\n",
    "\n",
    "print(df_result)\n",
    "\n",
    "# Plot Rápido\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Histórico recente\n",
    "plt.plot(bd['Date'].iloc[-60:], bd['Close'].iloc[-60:], label='Histórico Real', color='black')\n",
    "# Previsão\n",
    "plt.plot(df_result['Date'], df_result['Predict_Mean'], label='Média MC Dropout', color='blue')\n",
    "# Intervalo\n",
    "plt.fill_between(df_result['Date'], df_result['Lower_IC'], df_result['Upper_IC'], color='blue', alpha=0.2, label='Confiança (Incerteza do Modelo)')\n",
    "plt.title('Previsão BOVA11 usando Variação dos Neurônios (MC Dropout)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
